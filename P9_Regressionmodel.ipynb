{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674716ff-a908-4d94-b65b-504da6a77cb8",
   "metadata": {},
   "source": [
    "# Part 9: Random Forest regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46479126",
   "metadata": {},
   "source": [
    "The potency of the novel generated compounds for the BACE1 receptor will be determined with machine learning models. In this project will two different models be compared; a random forest regression model and a neuron network model. These models will be trained and validated with the filtered ChEMBL bioactivity data from part 3. In this part will the random forest regression model be trained and validated, followed by using the model to predict the potency of the novel compounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e24529-fed0-40f0-abbe-1e54cfd19132",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72272bb2-ab28-4bce-ab4f-85c6dd54d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from warnings import filterwarnings\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics, clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score, recall_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect\n",
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "import sys\n",
    "# sys.path.append(\"../../../\")\n",
    "# import teachopencadd\n",
    "# #import utils\n",
    "# #from teachopencadd import utils\n",
    "# from teachopencadd.utils import seed_everything\n",
    "# SEED = 22\n",
    "# seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284b34f-fa45-4dab-9463-06ada13bb436",
   "metadata": {},
   "source": [
    "\n",
    "Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc4f3a7-1546-46d7-a442-c900572213f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HERE = Path(_dh[-1])\n",
    "DATA = HERE / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d8f34-a935-45a6-a74c-1a631da75b77",
   "metadata": {},
   "source": [
    "Read filtered ChEMBL bioactivity data from part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac9cea5-912b-487a-bf6f-4efc967191ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe :  (6691, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  molecule_chembl_id    IC50 units  \\\n0      CHEMBL3969403  0.0002    nM   \n1      CHEMBL3937515  0.0009    nM   \n2      CHEMBL3949213  0.0010    nM   \n3      CHEMBL3955051  0.0018    nM   \n4      CHEMBL3936264  0.0057    nM   \n\n                                              smiles      pIC50  \\\n0  CC1(C)C(N)=N[C@](C)(c2cc(NC(=O)c3ccc(C#N)cn3)c...  12.698970   \n1  COc1cnc(C(=O)Nc2ccc(F)c([C@]3(C)CS(=O)(=O)C(C)...  12.045757   \n2  C[C@@]1(c2cc(NC(=O)c3ccc(C#N)cn3)ccc2F)CS(=O)(...  12.000000   \n3  CC1(C)C(N)=N[C@](C)(c2cc(NC(=O)c3cnc(C(F)F)cn3...  11.744727   \n4  C[C@@]1(c2cc(NC(=O)c3ccc(OC(F)F)cn3)ccc2F)CS(=...  11.244125   \n\n                                               graph  \n0  [(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...  \n1  [(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...  \n2  [(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...  \n3  [(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...  \n4  [(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>molecule_chembl_id</th>\n      <th>IC50</th>\n      <th>units</th>\n      <th>smiles</th>\n      <th>pIC50</th>\n      <th>graph</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CHEMBL3969403</td>\n      <td>0.0002</td>\n      <td>nM</td>\n      <td>CC1(C)C(N)=N[C@](C)(c2cc(NC(=O)c3ccc(C#N)cn3)c...</td>\n      <td>12.698970</td>\n      <td>[(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CHEMBL3937515</td>\n      <td>0.0009</td>\n      <td>nM</td>\n      <td>COc1cnc(C(=O)Nc2ccc(F)c([C@]3(C)CS(=O)(=O)C(C)...</td>\n      <td>12.045757</td>\n      <td>[(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CHEMBL3949213</td>\n      <td>0.0010</td>\n      <td>nM</td>\n      <td>C[C@@]1(c2cc(NC(=O)c3ccc(C#N)cn3)ccc2F)CS(=O)(...</td>\n      <td>12.000000</td>\n      <td>[(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CHEMBL3955051</td>\n      <td>0.0018</td>\n      <td>nM</td>\n      <td>CC1(C)C(N)=N[C@](C)(c2cc(NC(=O)c3cnc(C(F)F)cn3...</td>\n      <td>11.744727</td>\n      <td>[(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CHEMBL3936264</td>\n      <td>0.0057</td>\n      <td>nM</td>\n      <td>C[C@@]1(c2cc(NC(=O)c3ccc(OC(F)F)cn3)ccc2F)CS(=...</td>\n      <td>11.244125</td>\n      <td>[(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chembl_df = pd.read_pickle(DATA/\"BACE_compounds.pkl\",\n",
    "    # index_col=0,\n",
    ")\n",
    "\n",
    "print(\"Shape of dataframe : \", chembl_df.shape)\n",
    "chembl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3160da-d039-46e1-967f-a895027f2c04",
   "metadata": {},
   "source": [
    "Keep only the needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1f4868-61ea-44d0-b4b2-c5fe50cc1071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  molecule_chembl_id                                             smiles  \\\n0      CHEMBL3969403  CC1(C)C(N)=N[C@](C)(c2cc(NC(=O)c3ccc(C#N)cn3)c...   \n1      CHEMBL3937515  COc1cnc(C(=O)Nc2ccc(F)c([C@]3(C)CS(=O)(=O)C(C)...   \n2      CHEMBL3949213  C[C@@]1(c2cc(NC(=O)c3ccc(C#N)cn3)ccc2F)CS(=O)(...   \n3      CHEMBL3955051  CC1(C)C(N)=N[C@](C)(c2cc(NC(=O)c3cnc(C(F)F)cn3...   \n4      CHEMBL3936264  C[C@@]1(c2cc(NC(=O)c3ccc(OC(F)F)cn3)ccc2F)CS(=...   \n\n                                               graph      pIC50  \n0  [(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...  12.698970  \n1  [(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...  12.045757  \n2  [(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...  12.000000  \n3  [(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...  11.744727  \n4  [(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...  11.244125  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>molecule_chembl_id</th>\n      <th>smiles</th>\n      <th>graph</th>\n      <th>pIC50</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CHEMBL3969403</td>\n      <td>CC1(C)C(N)=N[C@](C)(c2cc(NC(=O)c3ccc(C#N)cn3)c...</td>\n      <td>[(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...</td>\n      <td>12.698970</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CHEMBL3937515</td>\n      <td>COc1cnc(C(=O)Nc2ccc(F)c([C@]3(C)CS(=O)(=O)C(C)...</td>\n      <td>[(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...</td>\n      <td>12.045757</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CHEMBL3949213</td>\n      <td>C[C@@]1(c2cc(NC(=O)c3ccc(C#N)cn3)ccc2F)CS(=O)(...</td>\n      <td>[(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CHEMBL3955051</td>\n      <td>CC1(C)C(N)=N[C@](C)(c2cc(NC(=O)c3cnc(C(F)F)cn3...</td>\n      <td>[(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...</td>\n      <td>11.744727</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CHEMBL3936264</td>\n      <td>C[C@@]1(c2cc(NC(=O)c3ccc(OC(F)F)cn3)ccc2F)CS(=...</td>\n      <td>[(x, [tensor([6, 0, 4, 5, 3, 0, 4, 0, 0]), ten...</td>\n      <td>11.244125</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chembl_df = chembl_df[[\"molecule_chembl_id\", \"smiles\", \"graph\", \"pIC50\"]]\n",
    "chembl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b2bc16-3a5e-4c4b-9eaa-7188c0b700e5",
   "metadata": {},
   "source": [
    "Add column for fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "compound_df = chembl_df.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set the number of folds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "N_FOLDS = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new training\n",
      "Epoch: 001, Train Acc: 1.3009, Test Acc: 1.3422\n",
      "Epoch: 002, Train Acc: 2.1338, Test Acc: 2.2462\n",
      "Epoch: 003, Train Acc: 1.0665, Test Acc: 1.1060\n",
      "Epoch: 004, Train Acc: 1.3353, Test Acc: 1.4625\n",
      "Epoch: 005, Train Acc: 1.0445, Test Acc: 1.1341\n",
      "Epoch: 006, Train Acc: 0.8354, Test Acc: 0.9053\n",
      "Epoch: 007, Train Acc: 1.0488, Test Acc: 1.0595\n",
      "Epoch: 008, Train Acc: 0.8267, Test Acc: 0.8829\n",
      "Epoch: 009, Train Acc: 1.1074, Test Acc: 1.2177\n",
      "Epoch: 010, Train Acc: 1.0440, Test Acc: 1.1602\n",
      "Epoch: 011, Train Acc: 1.0707, Test Acc: 1.1289\n",
      "Epoch: 012, Train Acc: 0.7903, Test Acc: 0.8848\n",
      "Epoch: 013, Train Acc: 0.7865, Test Acc: 0.9104\n",
      "Epoch: 014, Train Acc: 0.8224, Test Acc: 0.9060\n",
      "Epoch: 015, Train Acc: 0.8300, Test Acc: 0.8811\n",
      "Epoch: 016, Train Acc: 0.7692, Test Acc: 0.8444\n",
      "Epoch: 017, Train Acc: 0.7245, Test Acc: 0.8094\n",
      "Epoch: 018, Train Acc: 0.7625, Test Acc: 0.8555\n",
      "Epoch: 019, Train Acc: 0.9932, Test Acc: 1.1090\n",
      "Epoch: 020, Train Acc: 0.7704, Test Acc: 0.8471\n",
      "Epoch: 021, Train Acc: 0.7013, Test Acc: 0.7832\n",
      "Epoch: 022, Train Acc: 0.6669, Test Acc: 0.7338\n",
      "Epoch: 023, Train Acc: 0.8113, Test Acc: 0.9333\n",
      "Epoch: 024, Train Acc: 0.7179, Test Acc: 0.8169\n",
      "Epoch: 025, Train Acc: 0.8384, Test Acc: 0.9426\n",
      "Epoch: 026, Train Acc: 0.6688, Test Acc: 0.7506\n",
      "Epoch: 027, Train Acc: 0.6503, Test Acc: 0.7340\n",
      "Epoch: 028, Train Acc: 0.9736, Test Acc: 1.0852\n",
      "Epoch: 029, Train Acc: 0.8033, Test Acc: 0.9255\n",
      "Epoch: 030, Train Acc: 0.6789, Test Acc: 0.7970\n",
      "Epoch: 031, Train Acc: 0.6435, Test Acc: 0.7597\n",
      "Epoch: 032, Train Acc: 0.6455, Test Acc: 0.7435\n",
      "Epoch: 033, Train Acc: 0.6486, Test Acc: 0.7525\n",
      "Epoch: 034, Train Acc: 0.6604, Test Acc: 0.7570\n",
      "Epoch: 035, Train Acc: 0.8920, Test Acc: 0.9902\n",
      "Epoch: 036, Train Acc: 0.5849, Test Acc: 0.6861\n",
      "Epoch: 037, Train Acc: 0.7347, Test Acc: 0.8399\n",
      "Epoch: 038, Train Acc: 0.8858, Test Acc: 0.9838\n",
      "Epoch: 039, Train Acc: 0.7890, Test Acc: 0.9049\n",
      "new training\n",
      "Epoch: 001, Train Acc: 1.6196, Test Acc: 1.6024\n",
      "Epoch: 002, Train Acc: 1.1834, Test Acc: 1.1762\n",
      "Epoch: 003, Train Acc: 1.0519, Test Acc: 1.0696\n",
      "Epoch: 004, Train Acc: 1.1728, Test Acc: 1.1762\n",
      "Epoch: 005, Train Acc: 0.9300, Test Acc: 0.9681\n",
      "Epoch: 006, Train Acc: 1.7211, Test Acc: 1.6886\n",
      "Epoch: 007, Train Acc: 0.9343, Test Acc: 0.9858\n",
      "Epoch: 008, Train Acc: 0.9374, Test Acc: 0.9442\n",
      "Epoch: 009, Train Acc: 0.8282, Test Acc: 0.8850\n",
      "Epoch: 010, Train Acc: 0.9407, Test Acc: 1.0168\n",
      "Epoch: 011, Train Acc: 0.8146, Test Acc: 0.8563\n",
      "Epoch: 012, Train Acc: 0.9497, Test Acc: 0.9852\n",
      "Epoch: 013, Train Acc: 0.8898, Test Acc: 0.9256\n",
      "Epoch: 014, Train Acc: 0.8263, Test Acc: 0.8859\n",
      "Epoch: 015, Train Acc: 0.8385, Test Acc: 0.8942\n",
      "Epoch: 016, Train Acc: 0.7893, Test Acc: 0.8419\n",
      "Epoch: 017, Train Acc: 0.7620, Test Acc: 0.8333\n",
      "Epoch: 018, Train Acc: 0.7321, Test Acc: 0.7848\n",
      "Epoch: 019, Train Acc: 0.7033, Test Acc: 0.7784\n",
      "Epoch: 020, Train Acc: 0.8340, Test Acc: 0.9237\n",
      "Epoch: 021, Train Acc: 0.6972, Test Acc: 0.7693\n",
      "Epoch: 022, Train Acc: 0.8194, Test Acc: 0.9042\n",
      "Epoch: 023, Train Acc: 0.7599, Test Acc: 0.8795\n",
      "Epoch: 024, Train Acc: 0.7989, Test Acc: 0.8596\n",
      "Epoch: 025, Train Acc: 0.6551, Test Acc: 0.7516\n",
      "Epoch: 026, Train Acc: 0.6743, Test Acc: 0.7642\n",
      "Epoch: 027, Train Acc: 0.7445, Test Acc: 0.8224\n",
      "Epoch: 028, Train Acc: 0.6679, Test Acc: 0.7472\n",
      "Epoch: 029, Train Acc: 0.6901, Test Acc: 0.7581\n",
      "Epoch: 030, Train Acc: 0.6131, Test Acc: 0.7136\n",
      "Epoch: 031, Train Acc: 0.7452, Test Acc: 0.8072\n",
      "Epoch: 032, Train Acc: 0.6336, Test Acc: 0.7269\n",
      "Epoch: 033, Train Acc: 0.6146, Test Acc: 0.7105\n",
      "Epoch: 034, Train Acc: 0.7507, Test Acc: 0.8311\n",
      "Epoch: 035, Train Acc: 0.6080, Test Acc: 0.7209\n",
      "Epoch: 036, Train Acc: 0.6256, Test Acc: 0.7203\n",
      "Epoch: 037, Train Acc: 0.6671, Test Acc: 0.7610\n",
      "Epoch: 038, Train Acc: 0.5979, Test Acc: 0.6886\n",
      "Epoch: 039, Train Acc: 0.6564, Test Acc: 0.7599\n",
      "new training\n",
      "Epoch: 001, Train Acc: 1.1673, Test Acc: 1.1743\n",
      "Epoch: 002, Train Acc: 1.1528, Test Acc: 1.1493\n",
      "Epoch: 003, Train Acc: 1.1889, Test Acc: 1.1717\n",
      "Epoch: 004, Train Acc: 0.9729, Test Acc: 0.9988\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m splits \u001B[38;5;241m=\u001B[39m [train_x, test_x, train_y, test_y]\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# print(train_x)\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m \u001B[43mnn_training_and_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msplits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mGNN\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/ACMDD/main.py:97\u001B[0m, in \u001B[0;36mnn_training_and_validation\u001B[0;34m(name, splits, num_epochs, verbose)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, num_epochs):\n\u001B[1;32m     96\u001B[0m     train()\n\u001B[0;32m---> 97\u001B[0m     train_acc \u001B[38;5;241m=\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     98\u001B[0m     test_acc \u001B[38;5;241m=\u001B[39m test(test_dataloader)\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Train Acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Test Acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_acc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/GitHub/ACMDD/main.py:90\u001B[0m, in \u001B[0;36mnn_training_and_validation.<locals>.test\u001B[0;34m(dataloader)\u001B[0m\n\u001B[1;32m     88\u001B[0m loss \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data, y \u001B[38;5;129;01min\u001B[39;00m dataloader:  \u001B[38;5;66;03m# Iterate in batches over the training/test dataset.\u001B[39;00m\n\u001B[0;32m---> 90\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     91\u001B[0m     loss\u001B[38;5;241m.\u001B[39mappend(criterion(out\u001B[38;5;241m.\u001B[39msqueeze(), y)\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy())  \u001B[38;5;66;03m# Check against ground-truth labels.\u001B[39;00m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmean(loss)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Documents/GitHub/ACMDD/main.py:27\u001B[0m, in \u001B[0;36mGNN.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     24\u001B[0m x \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mx\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat)\n\u001B[1;32m     25\u001B[0m edge_attr \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39medge_attr\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat)\n\u001B[0;32m---> 27\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# 2. Readout layer\u001B[39;00m\n\u001B[1;32m     30\u001B[0m x \u001B[38;5;241m=\u001B[39m global_mean_pool(x, data\u001B[38;5;241m.\u001B[39mbatch)  \u001B[38;5;66;03m# [batch_size, hidden_channels]\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch_geometric/nn/models/basic_gnn.py:177\u001B[0m, in \u001B[0;36mBasicGNN.forward\u001B[0;34m(self, x, edge_index, edge_weight, edge_attr)\u001B[0m\n\u001B[1;32m    175\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs[i](x, edge_index, edge_weight\u001B[38;5;241m=\u001B[39medge_weight)\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupports_edge_attr:\n\u001B[0;32m--> 177\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    179\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs[i](x, edge_index)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch_geometric/nn/conv/gatv2_conv.py:236\u001B[0m, in \u001B[0;36mGATv2Conv.forward\u001B[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001B[0m\n\u001B[1;32m    230\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[1;32m    231\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe usage of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_attr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd_self_loops\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    232\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msimultaneously is currently not yet supported for \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    233\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_index\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in a \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSparseTensor\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m form\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    235\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: PairTensor, edge_attr: OptTensor)\u001B[39;00m\n\u001B[0;32m--> 236\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_l\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_r\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m                     \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    239\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:391\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[0;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    389\u001B[0m         aggr_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[0;32m--> 391\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maggregate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43maggr_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aggregate_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[1;32m    394\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (aggr_kwargs, ), out)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:514\u001B[0m, in \u001B[0;36mMessagePassing.aggregate\u001B[0;34m(self, inputs, index, ptr, dim_size)\u001B[0m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maggregate\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs: Tensor, index: Tensor,\n\u001B[1;32m    502\u001B[0m               ptr: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    503\u001B[0m               dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    504\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001B[39;00m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;124;03m    :math:`\\square_{j \\in \\mathcal{N}(i)}`.\u001B[39;00m\n\u001B[1;32m    506\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001B[39;00m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maggr_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    515\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_dim\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:114\u001B[0m, in \u001B[0;36mAggregation.__call__\u001B[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001B[0m\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m index\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m dim_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax()):\n\u001B[1;32m    110\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEncountered invalid \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdim_size\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    111\u001B[0m                          \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdim_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m but expected \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    112\u001B[0m                          \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>= \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py:21\u001B[0m, in \u001B[0;36mSumAggregation.forward\u001B[0;34m(self, x, index, ptr, dim_size, dim)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor, index: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     19\u001B[0m             ptr: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     20\u001B[0m             dim: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:153\u001B[0m, in \u001B[0;36mAggregation.reduce\u001B[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001B[0m\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m segment_csr(x, ptr, reduce\u001B[38;5;241m=\u001B[39mreduce)\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 153\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreduce\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch_geometric/utils/scatter.py:64\u001B[0m, in \u001B[0;36mscatter\u001B[0;34m(src, index, dim, out, dim_size, reduce)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscatter\u001B[39m(src: Tensor, index: Tensor, dim: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     62\u001B[0m             out: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     63\u001B[0m             reduce: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m---> 64\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch_scatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch_scatter/scatter.py:152\u001B[0m, in \u001B[0;36mscatter\u001B[0;34m(src, index, dim, out, dim_size, reduce)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;124;03m|\u001B[39;00m\n\u001B[1;32m     80\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;124;03m    torch.Size([10, 3, 64])\u001B[39;00m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msum\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mscatter_sum\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmul\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m scatter_mul(src, index, dim, out, dim_size)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/ACMDD/lib/python3.10/site-packages/torch_scatter/scatter.py:21\u001B[0m, in \u001B[0;36mscatter_sum\u001B[0;34m(src, index, dim, out, dim_size)\u001B[0m\n\u001B[1;32m     19\u001B[0m         size[dim] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     20\u001B[0m     out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(size, dtype\u001B[38;5;241m=\u001B[39msrc\u001B[38;5;241m.\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39msrc\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mout\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter_add_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out\u001B[38;5;241m.\u001B[39mscatter_add_(dim, index, src)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from main import nn_training_and_validation\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)#, random_state=SEED)\n",
    "for train_index, test_index in kf.split(compound_df):\n",
    "    print('new training')\n",
    "    train_x = compound_df.iloc[train_index].graph.to_list()\n",
    "    train_y = compound_df.iloc[train_index].pIC50.to_list()\n",
    "    test_x = compound_df.iloc[test_index].graph.to_list()\n",
    "    test_y = compound_df.iloc[test_index].pIC50.to_list()\n",
    "    splits = [train_x, test_x, train_y, test_y]\n",
    "    # print(train_x)\n",
    "\n",
    "    nn_training_and_validation(splits=splits, name='GNN')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "train_x[0].edge_attr.type()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fingerprints. The structures of the compounds will be transferred from SMILES notation to Morgan Fingerprints with a radius of 3, to explicitly describe the features of the compounds."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define function to convert the smiles into fingerprints"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def smiles_to_fp(smiles, method=\"maccs\", n_bits=2048):\n",
    "    \"\"\"\n",
    "    Encode a molecule from a SMILES string into a fingerprint.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles : str\n",
    "        The SMILES string defining the molecule.\n",
    "\n",
    "    method : str\n",
    "        The type of fingerprint to use. Default is MACCS keys.\n",
    "\n",
    "    n_bits : int\n",
    "        The length of the fingerprint.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        The fingerprint array.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # convert smiles to RDKit mol object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    if method == \"maccs\":\n",
    "        return np.array(MACCSkeys.GenMACCSKeys(mol))\n",
    "    if method == \"morgan2\":\n",
    "        return np.array(GetMorganFingerprintAsBitVect(mol, 2, nBits=n_bits))\n",
    "    if method == \"morgan3\":\n",
    "        return np.array(GetMorganFingerprintAsBitVect(mol, 3, nBits=n_bits))\n",
    "    else:\n",
    "        # NBVAL_CHECK_OUTPUT\n",
    "        print(f\"Warning: Wrong method specified: {method}. Default will be used instead.\")\n",
    "        return np.array(MACCSkeys.GenMACCSKeys(mol))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Moet dat niet later pas?]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use Morgan fingerprint with radius 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compound_df[\"fp\"] = compound_df[\"smiles\"].apply(smiles_to_fp, args=(\"morgan3\",))\n",
    "compound_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define function for machine learning model training and validation in a cross-validation loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Wat doet deze functie precies?]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def crossvalidation_reg(ml_model, df, n_folds=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Machine learning model training and validation in a cross-validation loop.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ml_model: sklearn model object\n",
    "        The machine learning model to train.\n",
    "    df: pd.DataFrame\n",
    "        Data set with SMILES and their associated activity labels.\n",
    "    n_folds: int, optional\n",
    "        Number of folds for cross-validation.\n",
    "    verbose: bool, optional\n",
    "        Performance measures are printed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    # Shuffle the indices for the k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)#, random_state=SEED)\n",
    "\n",
    "    # Results for each of the cross-validation folds\n",
    "    MAE_per_fold = []\n",
    "    RMSE_per_fold = []\n",
    "\n",
    "    # Loop over the folds\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        # clone model -- we want a fresh copy per fold!\n",
    "        fold_model = clone(ml_model)\n",
    "        # Training\n",
    "\n",
    "        # Convert the fingerprint and the label to a list\n",
    "        train_x = df.iloc[train_index].fp.tolist()\n",
    "        train_y = df.iloc[train_index].pIC50.tolist()\n",
    "\n",
    "        # Fit the model\n",
    "        fold_model.fit(train_x, train_y)\n",
    "\n",
    "        # Testing\n",
    "\n",
    "        # Convert the fingerprint and the label to a list\n",
    "        test_x = df.iloc[test_index].fp.tolist()\n",
    "        test_y = df.iloc[test_index].pIC50.tolist()\n",
    "\n",
    "        test_results = fold_model.predict(test_x)\n",
    "        # Prediction probability on test set\n",
    "        from sklearn import metrics\n",
    "\n",
    "        MAE_per_fold.append(metrics.mean_absolute_error(test_y, test_results))\n",
    "        #print('Mean Squared Error (MSE):', metrics.mean_squared_error(test_y, test_results))\n",
    "        RMSE_per_fold.append(np.sqrt(metrics.mean_squared_error(test_y, test_results)))\n",
    "\n",
    "        #from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "        #print(matthews_corrcoef(test_y, test_results))\n",
    "        #mape = np.mean(np.abs((gt - pred) / np.abs(gt)))\n",
    "        #print('Mean Absolute Percentage Error (MAPE):', round(mape * 100, 2))\n",
    "        #print('Accuracy:', round(100*(1 - mape), 2))\n",
    "    return(MAE_per_fold,RMSE_per_fold,fold_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random forest regressor model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The benefit of a regression model as opposed to a classification model is that it can not only predict if the new compound is active or inactive, but also the pIC50 value of the compound."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = [{\"label\": \"Model_RF_reg\", \"model\": RandomForestRegressor}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train model with RandomForestRegressor and show validation scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor()\n",
    "MAE, RMSE,trained_model = crossvalidation_reg(regressor , compound_df, n_folds=N_FOLDS)\n",
    "\n",
    "print(\n",
    "f\"Mean Absolute Error (MAE): {np.mean(MAE):.2f} \\t\"\n",
    "f\"and std : {np.std(MAE):.2f} \\n\"\n",
    "f\"Root Mean Square Error (RMSE): {np.mean(RMSE):.2f} \\t\"\n",
    "f\"and std : {np.std(RMSE):.2f} \\n\"\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compound_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "60dd91e6",
   "metadata": {},
   "source": [
    "To validate the performance of the model, the data was split into a train and test set. In this case this is done in a k-fold cross-validation. In this method, the data is split into k stratified folds. K separate models are trained, each with one of these folds as test data, and all other folds as training data. The k different calculated performances are then averaged for a more consistent performance overall. The errors between the predicted data and obtained experimental data are determined with a Mean Absolute Error (MAE) and a Root Mean Square Error (RMSE). \n",
    "\n",
    "[Herschrijven?]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878610af",
   "metadata": {},
   "source": [
    "[Zijn deze waarde oke? Hoe kunnen ze verbeterd worden? Below 0.6 quite decent?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab60106-aa04-4ff2-8f13-26cd5c081f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d21704a",
   "metadata": {},
   "source": [
    "This trained model will below be used to predict the pIC50 values of the novel, drug-like, generated compounds of part 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edba61b",
   "metadata": {},
   "source": [
    "### Generated Compounds: predict pIC50 with the trained random forest regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd58ad-8c2b-4be5-b5ed-ea9380f4d4f9",
   "metadata": {},
   "source": [
    "Read the filtered, generated compound data of part 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb309eb-9b50-4502-9562-11bd93a9a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "novelcompound_df = pd.read_csv(\n",
    "   DATA / \"generated_part8.csv\", index_col=0,\n",
    ")\n",
    "\n",
    "print(\"Shape of dataframe : \", novelcompound_df.shape)\n",
    "novelcompound_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39caaf5b-45db-4523-8745-ff858238efd0",
   "metadata": {},
   "source": [
    "List with SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96fdbc7-3b6d-490a-b534-b33d3d3a32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "novelcompound_df_smiles = novelcompound_df.SMILES.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54432b80",
   "metadata": {},
   "source": [
    "Convert SMILES to morgan fingerprints with radius 3. Use these fingerprints to predict the pIC50 of these compounds with the trained random forest regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91062a6f-6c6a-41ea-87a2-e9a834951047",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = []\n",
    "\n",
    "for smiles in novelcompound_df_smiles: \n",
    "    fp = smiles_to_fp(smiles,'morgan3')\n",
    "    fps.append(fp)\n",
    "\n",
    "predictions = trained_model.predict(fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47edd243",
   "metadata": {},
   "source": [
    "Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd0bab2-cf84-4010-b512-fec3ff7707d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "novelcompound_df_smiles_results = pd.DataFrame({\n",
    "\"SMILES\" : novelcompound_df_smiles,\n",
    "\"predicted_pIC50\" : predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2daa6a-4cff-4547-bebe-49f4c57c980e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "novelcompound_df_smiles_results_m = pd.merge(\n",
    "    novelcompound_df_smiles_results,\n",
    "    novelcompound_df,\n",
    "    on = \"SMILES\",\n",
    ")\n",
    "\n",
    "PandasTools.AddMoleculeColumnToFrame(novelcompound_df_smiles_results_m, smilesCol=\"SMILES\")\n",
    "novelcompound_df_smiles_results_m.sort_values(by=\"predicted_pIC50\", ascending = False, inplace = True)\n",
    "novelcompound_df_smiles_results_m.reset_index(drop=True, inplace=True)\n",
    "novelcompound_df_smiles_results_m.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cbbf84",
   "metadata": {},
   "source": [
    "[Say something about the results, is the pIC50 high? Do they fulfill Ro5? How do they look? Scaffold? Bestaan ze al? Zijn ze te synthesiseren?]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556d24c-5ee7-4fb4-bbf3-5b4e8b780e98",
   "metadata": {},
   "source": [
    "Save results of the novel compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3b4b3-89b7-459c-a7ae-7a65ac131d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = novelcompound_df_smiles_results_m.drop(\"ROMol\", axis = 1)\n",
    "output_df.to_csv(DATA/\"nieuwmoleculenlijst_voorspellingen.csv\")\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1a609-d4b8-4be2-bbe5-f450a42e071a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9497bdef-ab4e-4a4c-ac1a-f5fee7011dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
